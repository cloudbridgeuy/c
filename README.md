a
=

A CLI application to interact with OpenAI's ChatGPT API.

# Introduction

This project is heavily inspired by [`ddddddeon/a`](https://github.com/ddddddeon/a) which uses the
completion API to generate code from a text prompt. I used a fork of this project as base and modified
it to use the ChatGPT API instead.

The goal behind this API is to make it simple to ask code related questions to OpenAI ChatGPT API,
and get back code examples with its answers. I also named the CLI `a` because it allows for a very
idiomatic interface to query the API.

You should write your prompts using the programming language you want as the first word of your prompt
to get the correct syntax highlights for your code. If you don't you'll get your answer but without
any highlights.

All previous prompts and answers are stored on a file at `/tmp/a/last_request.json`, to be reused on
subsequent prompts. This improves the answers returned by the API and allows you to refer to previous
answers.

Since the ChatGPT `gpt-3.5-turbo` model only supports `4096` tokens, we only store past interactions
that amount to close to half the maximum amount of tokens. This is to give ChatGPT enough tokens to
create its response. The application will track errors regarding prompt size, and retry the request
with previous interactions up to five times before it gives up. This should guarantee an answer
almost any time.

You can also use the `/tmp/a/last_request.json` file to see all the stored interactions. Since the
file is stored as serialized `JSON` I suggest you use something like `yq` to read it.

```bash
yq -P /tmp/a/last_request.json
```

## Getting started

### OpenAI Key

To run the CLI you must provide your `OPEN_AI_KEY` as an environment variable. You can get your API
key [here](https://platform.openai.com/account/api-keys). Just sign-in with your credentials and click
`Create new secret key`. Copy the key and load it into a terminal session.

```bash
export OPEN_AI_KEY=<YOUR_API_KEY>
```

I suggest that you include this command in your `dotfiles` so it gets loaded automatically on all
terminal sessions.

### Install

You can download a pre-built binary from the [`Releases`](https://github.com/guzmonne/a/releases) page
or build it yourself using `cargo`. Some scripts are provided to simplify this task.

> The `./scripts/main` script requires [`argc`](https://github.com/sigoden/argc) to be installed on your system.

Once built, copy the `a` binary to any folder available on your path. Now you can start using it:

```bash
a bash script that echo '"Hello, World"' to the console
```

### Quotes

The main way of using `a` is by passing the prompt string directly after calling the binary. This means
that you're going to have to escape quotes and other characters that can get in the way because of the
way shell works. For example, if you want to use `backticks` to enclose variable names or `$` you're
going to have to escape them using single quotes. And if you want to escape single quotes use the `\`
character.

For example:

```bash
a bash script that creates a file called '"myfile.txt"' if the variable '`my_var`' doesn\'t exist
```

## System prompt

ChatGPT prompts are conformed of messages generated by three different personas:  `systen`, `user`,
and `assistant`. The `system` persona sends the first message, usually to tell ChatGPT what kind of
answer it should return. The prompt currently used by this CLI is:

```
You are a senior software engineer with years of experience working with multiple programming languages.
I'm going to ask you a series of questions regarding software engineering and I want you to answer them
by returning only code. The first word of each prompt represents the language you should use. All lines
that are not code should be represented as code comments. Always use two spaces for tabs.
```

I don't know if this is the best prompt to achieve the app goals but is the one that has been giving
me the best results.

The strength of this prompt is smaller than the one used by the `user` persona so you can change the
answers returned by ChatGPT by overriding the `system` command.

> There's currently no way of changing the `system` command dynamically yet.

## Comments

My goal was to get ChatGPT to return all the context information about the code formatted as code
comments. Hence the last sentence of the `system` prompt. Unfortunately, it doesn't always work as
expected. It doesn't take away from the AI responses but it makes the clipboard functionality less
useful since you need to cleanup the answer after you paste it in your editor.

## Stdin

You can also provide the ChatGPT prompt through `stdin`.

```bash
echo bash script that shows a spinner in the terminal | a
```

You can also use `stdin` when you need (or want) to write multi-line prompts or have to escape a
bunch of characters:

<pre><code>
{
tee <<-'EOF'
rust application that can scrap all the current Hackernews posts and returns a serialized
JSON object following this struct:

```rust
struct Post {
  index: String,
  url: String,
}
```

Please provide all information that is not related to code as code comments.
EOF
} | a
</code></pre>

Another good tool to use to write blocks of code in the terminal is [`gum`](https://github.com/charmbracelet/gum).
Here's how you would use it:

```bash
a <<<"$(gum write --placeholder "Details of this change (CTRL+D to finish)" --width=80 --height=20)"
```

If you feel is to verbose you can wrap it in a function:

```bash
function aa() {
  a <<<"$(gum write --placeholder "Details of this change (CTRL+D to finish)" --width=80 --height=20)"
}
```

Then you can just type `aa` and get directly to creating your prompt.

## Clipboard

Besides printing the response to the console and storing the answer on a file, the CLI also allows you
to copy the response to the clipboard automatically.

Give it a try.

## Debugging

The app comes with a built-in log that can be activated by setting the `RUST_LOG` variable to one
of these values:

- `debug`
- `info`
- `warn`
- `error`

If you set it to `debug` you'll see the payloads being used by the CLI.
